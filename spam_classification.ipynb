{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-02T19:37:00.532947Z",
     "start_time": "2024-08-02T19:37:00.526739Z"
    }
   },
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder  # converts categorical labels into numerical values.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:31:23.231266Z",
     "start_time": "2024-08-02T19:31:23.218681Z"
    }
   },
   "cell_type": "code",
   "source": "spam_data = pd.read_csv('spam.csv', encoding='latin-1', usecols=[0, 1], names=['label', 'message'], skiprows=1)",
   "id": "da3fd5006c42cda1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:31:34.790230Z",
     "start_time": "2024-08-02T19:31:34.786367Z"
    }
   },
   "cell_type": "code",
   "source": "print(spam_data.head())",
   "id": "32b5df9dc4f39518",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:32:01.067943Z",
     "start_time": "2024-08-02T19:32:01.062676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# converting label to 0 for ham and 1 for spam\n",
    "label_encoder = LabelEncoder()\n",
    "spam_data['label'] = label_encoder.fit_transform(spam_data['label'])"
   ],
   "id": "6439dac37ea83be7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:32:02.370615Z",
     "start_time": "2024-08-02T19:32:02.366919Z"
    }
   },
   "cell_type": "code",
   "source": "print(spam_data.head())",
   "id": "80a3c40b898dce15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            message\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "16aa0a5e6f3ed155"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Processing",
   "id": "28f16c21724c9036"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Cleaning",
   "id": "1a1b3cf0aa43410a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:32:06.702728Z",
     "start_time": "2024-08-02T19:32:06.246349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing Punctuations & Special Characters\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "spam_data['cleaned_message'] = spam_data['message'].apply(process_text)\n",
    "spam_data.drop(columns=['message'], inplace=True)"
   ],
   "id": "4c71379ed12f506b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jiyamakhija/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:32:12.479479Z",
     "start_time": "2024-08-02T19:32:12.476114Z"
    }
   },
   "cell_type": "code",
   "source": "print(spam_data.head())",
   "id": "a061975b37e91bfb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                    cleaned_message\n",
      "0      0  go until jurong point crazy available only in ...\n",
      "1      0                            ok lar joking wif u oni\n",
      "2      1  free entry in 2 a wkly comp to win fa cup fina...\n",
      "3      0        u dun say so early hor u c already then say\n",
      "4      0  nah i do think he goes to usf he lives around ...\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenization",
   "id": "101fabf0267d88a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3bd905f274e618fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preparing Data\n",
    "### Splitting the data into training (60%), validation (20%), and test (20%)"
   ],
   "id": "6adbb20a28ec5886"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T19:33:44.426550Z",
     "start_time": "2024-08-02T19:33:44.160337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into training (60%) and temp (40%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, spam_data['label'], test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the temp set into validation (20%) and test (20%) sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ],
   "id": "87dab6b76f4c0bb9",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Split the data into training (60%) and temp (40%) sets\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m X_train, X_temp, y_train, y_temp \u001B[38;5;241m=\u001B[39m train_test_split(\u001B[43mX\u001B[49m, spam_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m], test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.4\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Split the temp set into validation (20%) and test (20%) sets\u001B[39;00m\n\u001B[1;32m      5\u001B[0m X_val, X_test, y_val, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X_temp, y_temp, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6b78e15a4c94e612"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4357f4625d008e21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
